{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf9bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nband/uncertainty-challenge/sdc_motion_prediction/ysdc_dataset_api/utils/transform.py:90: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, C))\n",
      "  res = transform @ ph\n",
      "/miniconda3/envs/yandex/lib/python3.8/site-packages/numba/core/typing/npydecl.py:937: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, C))\n",
      "  warnings.warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "from ysdc_dataset_api.dataset import MotionPredictionDataset\n",
    "from ysdc_dataset_api.features import FeatureRenderer\n",
    "from ysdc_dataset_api.utils import get_file_paths, scenes_generator, transform_2d_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077c7d5",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd30c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/path/to/dataset/train/'\n",
    "filepaths = get_file_paths(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = next(scenes_generator(filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374975ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of known history steps\n",
    "# Index 0 is farthest (-5s) into the past, and index 24 represents current time\n",
    "print('Number of history steps:', len(scene.past_vehicle_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of vehicles seen at current time:', len(scene.past_vehicle_tracks[-1].tracks))\n",
    "print(scene.past_vehicle_tracks[-1].tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38380136",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of pedestrians seen at current time:', len(scene.past_pedestrian_tracks[-1].tracks))\n",
    "print(scene.past_pedestrian_tracks[-1].tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a10aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of vehicles to predict:', len(scene.prediction_requests))\n",
    "print(scene.prediction_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of future steps\n",
    "# Index 0 is closest (0.2s into the future), index 24 is farthest (5s into the future)\n",
    "print('Number of future steps to predict:', len(scene.future_vehicle_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf4adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First future state:', scene.future_vehicle_tracks[0].tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Last future state:', scene.future_vehicle_tracks[24].tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52f8de",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer_config = {\n",
    "    # parameters of feature maps to render\n",
    "    'feature_map_params': {\n",
    "        'rows': 400,\n",
    "        'cols': 400,\n",
    "        'resolution': 0.25,  # number of meters in one pixel\n",
    "    },\n",
    "    'renderers_groups': [\n",
    "        # Having several feature map groups\n",
    "        # allows to independently render feature maps with different history length.\n",
    "        # This could be useful to render static features (road graph, etc.) once.\n",
    "        {\n",
    "            # start: int, first timestamp into the past to render, 0 – prediction time\n",
    "            # stop: int, last timestamp to render inclusively, 24 – farthest known point into the past\n",
    "            # step: int, grid step size,\n",
    "            #            step=1 renders all points between start and stop,\n",
    "            #            step=2 renders every second point, etc.\n",
    "            'time_grid_params': {\n",
    "                'start': 0,\n",
    "                'stop': 0,\n",
    "                'step': 1,\n",
    "            },\n",
    "            'renderers': [\n",
    "                # each value is rendered at its own channel\n",
    "                # occupancy -- 1 channel\n",
    "                # velocity -- 2 channels (x, y)\n",
    "                # acceleration -- 2 channels (x, y)\n",
    "                # yaw -- 1 channel\n",
    "                {'vehicles': ['occupancy', 'velocity', 'acceleration', 'yaw']},\n",
    "                # only occupancy and velocity are available for pedestrians\n",
    "                {'pedestrians': ['occupancy', 'velocity']},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'time_grid_params': {\n",
    "                'start': 0,\n",
    "                'stop': 0,\n",
    "                'step': 1,\n",
    "            },\n",
    "            'renderers': [\n",
    "                {\n",
    "                    'road_graph': [\n",
    "                        'crosswalk_occupancy',\n",
    "                        'crosswalk_availability',\n",
    "                        # 'lane_availability',  # Currently unavailable due to problem in dataset\n",
    "                        'lane_direction',\n",
    "                        'lane_occupancy',\n",
    "                        'lane_priority',\n",
    "                        'lane_speed_limit',\n",
    "                        'road_polygons',\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset dir containing sub directories\n",
    "dataset_path = '/path/to/dataset/train/'\n",
    "# path to file with scene tags\n",
    "scene_tags_fpath = '/path/to/dataset/train_tags_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = FeatureRenderer(renderer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.to_feature_map_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionPredictionDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    scene_tags_fpath=scene_tags_fpath,\n",
    "    feature_producer=renderer,\n",
    "    transform_ground_truth_to_agent_frame=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of scenes in dataset.\n",
    "# Actual number of objects in dataset is bigger,\n",
    "# since we consider multiple agents in a scene for prediction.\n",
    "dataset.num_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take some scene\n",
    "for i in range(10):\n",
    "    data_item = next(dataset_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f300b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One data item contains rendered feature maps and ground truth trajectory.\n",
    "# Feature maps are centered around current actor.\n",
    "# Ground truth trajectory is transformed to actor coordinate system:\n",
    "# actor is located at origin (0, 0) headed to positive x direction  at prediction time.\n",
    "data_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3812904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature maps are in channels first format\n",
    "data_item['feature_maps'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c44e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vehicles occupancy, pedestrian occupancy, lane occupancy and road polygon\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(data_item['feature_maps'][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(data_item['feature_maps'][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(data_item['feature_maps'][12], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(data_item['feature_maps'][15], origin='lower', cmap='binary', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce542b7",
   "metadata": {},
   "source": [
    "## Filtration by tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To filter scenes by tags one should specify a filter function\n",
    "# Scene tags dict has following structure:\n",
    "# {\n",
    "#     'day_time': one of {'kNight', 'kMorning', 'kAfternoon', 'kEvening'}\n",
    "#     'season': one of {'kWinter', 'kSpring', 'kSummer', 'kAutumn'}\n",
    "#     'track': one of {'Moscow' , 'Skolkovo', 'Innopolis', 'AnnArbor', 'Modiin', 'TelAviv'}\n",
    "#     'sun_phase': one of {'kAstronomicalNight', 'kTwilight', 'kDaylight'}\n",
    "#     'precipitation': one of {'kNoPrecipitation', 'kRain', 'kSleet', 'kSnow'}\n",
    "# }\n",
    "# Full description of protobuf message is available at tags.proto file in sources\n",
    "\n",
    "\n",
    "def filter_scene(scene_tags_dict):\n",
    "    if scene_tags_dict['track'] == 'AnnArbor' and scene_tags_dict['precipitation'] == 'kRain':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90601855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory tags list can include any number of the following non-mutually exclusive tags.\n",
    "# [\n",
    "#     'kMoveLeft', 'kMoveRight', 'kMoveForward', 'kMoveBack',\n",
    "#     'kAcceleration', 'kDeceleration', 'kUniform',\n",
    "#     'kStopping', 'kStarting', 'kStationary'\n",
    "# ]\n",
    "\n",
    "\n",
    "def filter_trajectory(trajectory_tags_list):\n",
    "    if 'kMoveRight' in trajectory_tags_list:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1735d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to filter scenes\n",
    "\n",
    "dataset = MotionPredictionDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    scene_tags_fpath=scene_tags_fpath,\n",
    "    feature_producer=renderer,\n",
    "    transform_ground_truth_to_agent_frame=True,\n",
    "    scene_tags_filter=filter_scene,\n",
    "    trajectory_tags_filter=filter_trajectory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainy Ann-Arbor is pretty rare occasion\n",
    "dataset.num_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3494967",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    data_item = next(dataset_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_gt = transform2dpoints(data_item['ground_truth_trajectory'], renderer.to_feature_map_tf)\n",
    "transformed_gt = np.round(transformed_gt - 0.5).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ef238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like car is moving right\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(data_item['feature_maps'][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(data_item['feature_maps'][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(data_item['feature_maps'][12], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(data_item['feature_maps'][15], origin='lower', cmap='binary', alpha=0.1)\n",
    "ax = plt.gca()\n",
    "ax.add_collection(mc.LineCollection([transformed_gt], color='green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d19bd",
   "metadata": {},
   "source": [
    "## Prerendered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe587818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use raw protobuf dataset here to extract ground truth trajectories\n",
    "prerenderer_dataset = MotionPredictionDataset(\n",
    "    dataset_path='/path/to/dataset/train/',\n",
    "    scene_tags_fpath='/path/to/dataset/train_tags_file',\n",
    "    prerendered_dataset_path='/path/to/pre_rendered_dataset/train/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed304927",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(prerenderer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d322c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    item = next(dataset_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(item['prerendered_feature_map'][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(item['prerendered_feature_map'][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(item['prerendered_feature_map'][13], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(item['prerendered_feature_map'][16], origin='lower', cmap='binary', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d457ecd",
   "metadata": {},
   "source": [
    "## Model evluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28df53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ood_validation_data(scene_tags_dict):\n",
    "    if (scene_tags_dict['track'] in ['Skolkovo', 'Modiin', 'TelAviv'] and\n",
    "        scene_tags_dict[\n",
    "            'precipitation'] in ['kNoPrecipitation', 'kRain', 'kSnow']):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24daa573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6023/500000 scenes fit the filter criteria.\n"
     ]
    }
   ],
   "source": [
    "ood_validation_dataset = MotionPredictionDataset(\n",
    "    dataset_path='/path/to/nips_dataset/validation/',\n",
    "    prerendered_dataset_path='/path/to/pre_rendered_dataset/validation/',\n",
    "    scene_tags_fpath='/path/to/nips_dataset/validation_scene_tags_with_prec.txt',\n",
    "    scene_tags_filter=filter_ood_validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bdc940b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6023"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_validation_dataset.num_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8647dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdc.config import build_parser\n",
    "\n",
    "parser = build_parser()\n",
    "args = parser.parse_args('')\n",
    "\n",
    "def ipynb_patch_args(args):\n",
    "    args.dir_checkpoint = '/path/to/model_checkpoints'\n",
    "\n",
    "    # Backbone model details\n",
    "    # Deep Imitative Model: MobileNetv2 feature encoder, autoregressive flow decoder\n",
    "    args.model_name = 'dim'\n",
    "    args.model_dim_hidden = 512\n",
    "    args.exp_device = 'cuda:0'\n",
    "\n",
    "    # Used in scoring generated trajectories and obtaining per-plan/per-scene confidence scores.\n",
    "    # See `sdc.oatomobile.torch.baselines.robust_imitative_planning.py` for details.\n",
    "    args.rip_per_plan_algorithm = 'LQ'\n",
    "    args.rip_per_scene_algorithm = 'LQ'\n",
    "\n",
    "    # Number of ensemble members\n",
    "    args.rip_k = 3\n",
    "\n",
    "    # Data loading\n",
    "    args.exp_batch_size = 32\n",
    "    args.data_num_workers = 4\n",
    "    args.data_prefetch_factor = 2\n",
    "\n",
    "    return args\n",
    "\n",
    "c = ipynb_patch_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129e482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIP kwargs:\n",
      "{'device': 'cuda:0',\n",
      " 'k': 3,\n",
      " 'model_name': 'bc',\n",
      " 'num_preds': 5,\n",
      " 'per_plan_algorithm': 'LQ',\n",
      " 'per_scene_algorithm': 'LQ',\n",
      " 'samples_per_model': 10}\n",
      "Building RIP agent with backbone model bc, per-plan algorithm LQ, per-scene algorithm LQ, 3 ensemble members.\n",
      "Model kwargs:\n",
      "{'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n",
      "Model kwargs:\n",
      "{'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n",
      "Model kwargs:\n",
      "{'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nband/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "Using cache found in /home/nband/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "Using cache found in /home/nband/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f1b21e8452e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Initialize and load ensemble of k models from checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f1b21e8452e8>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_rip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{c.dir_checkpoint}/{full_model_name}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         model = load_rip_checkpoints(\n\u001b[0m\u001b[1;32m     13\u001b[0m             model=model, device=c.exp_device, k=c.rip_k, checkpoint_dir=checkpoint_dir)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uncertainty-challenge/sdc_motion_prediction/sdc/oatomobile/torch/baselines/robust_imitative_planning.py\u001b[0m in \u001b[0;36mload_rip_checkpoints\u001b[0;34m(model, device, k, checkpoint_dir)\u001b[0m\n\u001b[1;32m    204\u001b[0m ) -> RIPAgent:\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         raise ValueError(\n\u001b[1;32m    208\u001b[0m             \u001b[0;34mf'Expected trained model checkpoints for RIP at '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/yandex/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/yandex/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/yandex/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/yandex/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/path'"
     ]
    }
   ],
   "source": [
    "from sdc.oatomobile.torch.baselines import init_rip\n",
    "from sdc.oatomobile.torch.baselines.robust_imitative_planning import load_rip_checkpoints\n",
    "from typing import Mapping\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "\n",
    "        # Initialize torch hub dir\n",
    "        torch.hub.set_dir(f'{c.dir_checkpoint}/torch_hub')\n",
    "\n",
    "    def load(self):\n",
    "        model, full_model_name, _, _ = init_rip(c=self.c)\n",
    "        checkpoint_dir = f'{c.dir_checkpoint}/{full_model_name}'\n",
    "        self.model = load_rip_checkpoints(\n",
    "            model=model, device=c.exp_device, k=c.rip_k,\n",
    "            checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "    def predict(self, batch: Mapping[str, torch.Tensor]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch: Mapping[str, torch.Tensor], with 'feature_maps' key/value\n",
    "\n",
    "        Returns:\n",
    "            Sequence of dicts. Each has the following structure:\n",
    "                {\n",
    "                    predictions_list: Sequence[np.ndarray],\n",
    "                    plan_confidence_scores_list: Sequence[np.ndarray],\n",
    "                    pred_request_confidence_score: float,\n",
    "                }\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        predictions, plan_confidence_scores, pred_request_confidence_scores = (\n",
    "            self.model(**batch))\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "        plan_confidence_scores = plan_confidence_scores.detach().cpu().numpy()\n",
    "        pred_request_confidence_scores = pred_request_confidence_scores.detach().cpu().numpy()\n",
    "        return [\n",
    "            {\n",
    "                'predictions_list': predictions[i],\n",
    "                'plan_confidence_scores_list': plan_confidence_scores[i],\n",
    "                'pred_request_confidence_score':\n",
    "                    pred_request_confidence_scores[i]\n",
    "            } for i in range(predictions.shape[0])]\n",
    "\n",
    "# Initialize and load ensemble of k models from checkpoints\n",
    "model = Model(c=c)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Init dataloader\n",
    "dataloader_kwargs = {\n",
    "    'batch_size': c.exp_batch_size,\n",
    "    'num_workers': c.data_num_workers,\n",
    "    'prefetch_factor': c.data_prefetch_factor,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "print(f'Building dataloaders with kwargs {dataloader_kwargs}.')\n",
    "ood_validation_dataloader = torch.utils.data.DataLoader(ood_validation_dataset, **dataloader_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ysdc_dataset_api.evaluation import Submission, object_prediction_from_model_output, save_submission_proto\n",
    "from sdc.oatomobile.torch.baselines import batch_transform\n",
    "import tqdm.notebook as tqdm\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75004538",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = Submission()\n",
    "\n",
    "batch_cast = partial(\n",
    "    batch_transform, device=c.exp_device, downsample_hw=None,\n",
    "    data_use_prerendered=True)\n",
    "\n",
    "for batch in tqdm.tqdm(ood_validation_dataloader):\n",
    "    batch_output = model.predict(batch_cast(batch))\n",
    "\n",
    "    for i, data_item_output in enumerate(batch_output):\n",
    "        proto = object_prediction_from_model_output(\n",
    "            track_id=batch['track_id'][i],\n",
    "            scene_id=batch['scene_id'][i],\n",
    "            model_output=data_item_output)\n",
    "\n",
    "        submission.predictions.append(proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission_proto('/path/to/submission.pb', submission=submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}