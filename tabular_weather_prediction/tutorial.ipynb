{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Weather Prediction Tutorial\n",
    "\n",
    "This tutorial steps through the uncertainty challenge on tabular weather data for regression.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Data Loading\n",
    "2. Training\n",
    "3. Inference\n",
    "4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "All data is provided as csv files. You should have downloaded the following data files:\n",
    "\n",
    "- `train.csv`\n",
    "- `dev_in.csv`\n",
    "- `dev_out.csv`\n",
    "\n",
    "`dev_in` consists of data in-domain with `train` in terms of time and climate. `dev_out` consists of data shifted in time and climates with respect to `train`.\n",
    "\n",
    "This tutorial will assume that all data files are placed in a local directory named `./data/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_time</th>\n",
       "      <th>fact_latitude</th>\n",
       "      <th>fact_longitude</th>\n",
       "      <th>fact_temperature</th>\n",
       "      <th>fact_cwsm_class</th>\n",
       "      <th>climate</th>\n",
       "      <th>topography_bathymetry</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>climate_temperature</th>\n",
       "      <th>climate_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>cmc_0_1_66_0_grad</th>\n",
       "      <th>cmc_0_1_66_0_next</th>\n",
       "      <th>cmc_0_1_67_0_grad</th>\n",
       "      <th>cmc_0_1_67_0_next</th>\n",
       "      <th>cmc_0_1_68_0_grad</th>\n",
       "      <th>cmc_0_1_68_0_next</th>\n",
       "      <th>gfs_2m_dewpoint_grad</th>\n",
       "      <th>gfs_2m_dewpoint_next</th>\n",
       "      <th>gfs_total_clouds_cover_low_grad</th>\n",
       "      <th>gfs_total_clouds_cover_low_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.543321e+09</td>\n",
       "      <td>26.968800</td>\n",
       "      <td>-99.248901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-17.526443</td>\n",
       "      <td>14.613571</td>\n",
       "      <td>754.263405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.600006</td>\n",
       "      <td>-2.750006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.538776e+09</td>\n",
       "      <td>29.374201</td>\n",
       "      <td>-100.927002</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>297.0</td>\n",
       "      <td>41.531032</td>\n",
       "      <td>26.992143</td>\n",
       "      <td>733.117168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.600006</td>\n",
       "      <td>17.950006</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.552115e+09</td>\n",
       "      <td>22.149599</td>\n",
       "      <td>113.592003</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>43.916531</td>\n",
       "      <td>18.842143</td>\n",
       "      <td>761.571076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233978</td>\n",
       "      <td>21.450006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.549566e+09</td>\n",
       "      <td>34.678699</td>\n",
       "      <td>-86.684799</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mild temperate</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.240955</td>\n",
       "      <td>8.303571</td>\n",
       "      <td>747.524910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>16.150018</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.552910e+09</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>41.966667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.394660</td>\n",
       "      <td>6.451429</td>\n",
       "      <td>753.168113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>3.150018</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fact_time  fact_latitude  fact_longitude  fact_temperature  \\\n",
       "0  1.543321e+09      26.968800      -99.248901               2.0   \n",
       "1  1.538776e+09      29.374201     -100.927002              31.0   \n",
       "2  1.552115e+09      22.149599      113.592003              17.0   \n",
       "3  1.549566e+09      34.678699      -86.684799              24.0   \n",
       "4  1.552910e+09      46.066667       41.966667               9.0   \n",
       "\n",
       "   fact_cwsm_class         climate  topography_bathymetry  sun_elevation  \\\n",
       "0              0.0             dry                  127.0     -17.526443   \n",
       "1             20.0  mild temperate                  297.0      41.531032   \n",
       "2             10.0  mild temperate                   -1.0      43.916531   \n",
       "3             20.0  mild temperate                  193.0      40.240955   \n",
       "4             20.0             dry                   90.0      30.394660   \n",
       "\n",
       "   climate_temperature  climate_pressure  ...  cmc_0_1_66_0_grad  \\\n",
       "0            14.613571        754.263405  ...                0.0   \n",
       "1            26.992143        733.117168  ...                0.0   \n",
       "2            18.842143        761.571076  ...                0.0   \n",
       "3             8.303571        747.524910  ...                0.0   \n",
       "4             6.451429        753.168113  ...                0.0   \n",
       "\n",
       "   cmc_0_1_66_0_next  cmc_0_1_67_0_grad  cmc_0_1_67_0_next  cmc_0_1_68_0_grad  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   cmc_0_1_68_0_next  gfs_2m_dewpoint_grad  gfs_2m_dewpoint_next  \\\n",
       "0                0.0             -2.600006             -2.750006   \n",
       "1                0.0             -0.600006             17.950006   \n",
       "2                0.0             -0.233978             21.450006   \n",
       "3                0.0              0.059448             16.150018   \n",
       "4                0.0              0.400024              3.150018   \n",
       "\n",
       "   gfs_total_clouds_cover_low_grad  gfs_total_clouds_cover_low_next  \n",
       "0                              0.0                              0.0  \n",
       "1                            -12.0                             11.0  \n",
       "2                              1.0                              8.0  \n",
       "3                            -58.0                             41.0  \n",
       "4                             18.0                             92.0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load each data file as a pandas data frame\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_in = pd.read_csv('data/dev_in.csv')\n",
    "df_dev_out = pd.read_csv('data/dev_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "In this tutorial, the `CatBoostRegressor` is used as the model.\n",
    "- An ensemble of models are trained.\n",
    "- It is important to use `RMSEWithUncertainty` as the loss function during training time in order to be able to calculate uncertainty measures during inference.\n",
    "- The models are trained using `df_train` and the hyperparameters should be finetuned using `df_dev_in`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and targets, and remove redundant meta-data\n",
    "X_train = df_train.iloc[:,6:]\n",
    "X_dev_in = df_dev_in.iloc[:,6:]\n",
    "y_train = df_train['fact_temperature']\n",
    "y_dev_in = df_dev_in['fact_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training hyperparameters (note these are dummy hyperparameters - you will need to select your own)\n",
    "ensemble_size = 3\n",
    "depth = 2\n",
    "iterations = 200\n",
    "learning_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model index: 0\n",
      "\n",
      "0:\tlearn: 10.0802549\ttest: 10.0807415\tbest: 10.0807415 (0)\ttotal: 1.39s\tremaining: 4m 37s\n",
      "100:\tlearn: 2.8927387\ttest: 2.8976019\tbest: 2.8976019 (100)\ttotal: 2m 12s\tremaining: 2m 9s\n",
      "199:\tlearn: 2.4620033\ttest: 2.4656851\tbest: 2.4656851 (199)\ttotal: 4m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.465685117\n",
      "bestIteration = 199\n",
      "\n",
      "\n",
      " Model index: 1\n",
      "\n",
      "0:\tlearn: 10.0797417\ttest: 10.0802326\tbest: 10.0802326 (0)\ttotal: 1.4s\tremaining: 4m 38s\n",
      "100:\tlearn: 2.8949066\ttest: 2.9003376\tbest: 2.9003376 (100)\ttotal: 2m 11s\tremaining: 2m 8s\n",
      "199:\tlearn: 2.4643793\ttest: 2.4687305\tbest: 2.4687305 (199)\ttotal: 4m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.46873047\n",
      "bestIteration = 199\n",
      "\n",
      "\n",
      " Model index: 2\n",
      "\n",
      "0:\tlearn: 10.0784878\ttest: 10.0789484\tbest: 10.0789484 (0)\ttotal: 1.54s\tremaining: 5m 5s\n",
      "100:\tlearn: 2.8949230\ttest: 2.9001259\tbest: 2.9001259 (100)\ttotal: 3m 29s\tremaining: 3m 25s\n",
      "199:\tlearn: 2.4657170\ttest: 2.4698817\tbest: 2.4698817 (199)\ttotal: 6m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.469881685\n",
      "bestIteration = 199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train ensemble of models\n",
    "\n",
    "import catboost\n",
    "\n",
    "trained_models = []\n",
    "for seed in range(ensemble_size):\n",
    "    \n",
    "    model = catboost.CatBoostRegressor(\n",
    "        learning_rate = learning_rate,\n",
    "        iterations = iterations,\n",
    "        depth = depth,\n",
    "        loss_function = 'RMSEWithUncertainty',\n",
    "        eval_metric = 'RMSE',\n",
    "        random_seed = seed)\n",
    "    \n",
    "    print(f'\\n Model index: {seed}\\n')\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose = 100,\n",
    "        eval_set = (X_dev_in, y_dev_in))\n",
    "    \n",
    "    trained_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference\n",
    "\n",
    "All inference in this section is carried out on a combined dataset of `dev_in` + `dev_out` = `dev`.\n",
    "The objective here is two fold:\n",
    "\n",
    "1. Evaluate the ensemble of trained models to get predictions for each data point\n",
    "2. Use the predictions to determine an uncertainty score for each data point using any chosen uncertainty measure\n",
    "\n",
    "It is hoped that the uncertainty measure chosen ensures that data points with greater errors yield greater uncertainties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined evaluation dataset and keep only the features (and extract the target)\n",
    "df_dev = pd.concat([df_dev_in, df_dev_out])\n",
    "X_dev = df_dev.iloc[:,6:]\n",
    "y_dev = df_dev['fact_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ensemble of predictions for each data point\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_predictions(features_df, model):\n",
    "    '''\n",
    "    Calculates predictions on df features for specified model\n",
    "    \n",
    "    Return: array [num_samples x 2],\n",
    "        where\n",
    "            num_samples = number of rows in features_df\n",
    "            2 = [mean, variance]\n",
    "    \n",
    "    '''\n",
    "    return model.predict(features_df)\n",
    "\n",
    "\n",
    "def get_all_predictions(features_df, models_list):\n",
    "    '''\n",
    "    Return: array [ensemble_size x num_samples x 2],\n",
    "        where\n",
    "            ensemble_size = number of models in models_list\n",
    "            num_samples = number of rows in features_df\n",
    "            2 = [mean, variance]\n",
    "    '''\n",
    "    all_preds = []\n",
    "    for model in models_list:\n",
    "        preds = np.asarray(get_predictions(features_df, model))\n",
    "        all_preds.append(preds)\n",
    "    return np.stack(all_preds, axis=0)\n",
    "\n",
    "\n",
    "all_preds = get_all_predictions(X_dev, trained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose any uncertainty measure to calculate uncertainty scores\n",
    "# This tutorial uses total variance as the uncertainty measure\n",
    "\n",
    "def calculate_tvar(preds):\n",
    "    '''\n",
    "    preds: array [ensemble_size x num_samples x 2]\n",
    "    '''\n",
    "    \n",
    "    var_mean = np.var(preds[:, :, 0], axis=0)\n",
    "    mean_var = np.mean(preds[:, :, 1], axis=0)\n",
    "    tvar = var_mean + mean_var\n",
    "    return tvar\n",
    "\n",
    "uncertainties = calculate_tvar(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission\n",
    "\n",
    "A csv file in a specific format has to be prepared for submission. It is important that the submission is for the combined dataset of `dev_in` + `dev_out` = `dev`, where order of concatenation is as stated - this is to ensure all given IDs are correct at submission time.\n",
    "\n",
    "The submitted csv file should contain the following columns:\n",
    "- ID\n",
    "- PRED\n",
    "- UNCERTAINTY\n",
    "- TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRED</th>\n",
       "      <th>UNCERTAINTY</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.687017</td>\n",
       "      <td>12.973079</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.991255</td>\n",
       "      <td>5.027490</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27.329121</td>\n",
       "      <td>11.576975</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24.717714</td>\n",
       "      <td>5.861262</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>34.800635</td>\n",
       "      <td>18.719108</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       PRED  UNCERTAINTY  TARGET\n",
       "0   1  32.687017    12.973079    35.0\n",
       "1   2   7.991255     5.027490     6.0\n",
       "2   3  27.329121    11.576975    29.0\n",
       "3   4  24.717714     5.861262    27.0\n",
       "4   5  34.800635    18.719108    37.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the ids\n",
    "ids = np.arange(1, len(df_dev) + 1)\n",
    "\n",
    "# Predictions are the mean predictions across the ensemble of models\n",
    "preds = np.mean(all_preds[:,:,0], axis=0)\n",
    "\n",
    "# Targets have already been extracted\n",
    "targets = y_dev\n",
    "\n",
    "# The uncertainties have been calculated in the previous step\n",
    "\n",
    "# Store all the information to be submitted in a df\n",
    "df_submission = pd.DataFrame(data={\n",
    "        'ID' : ids,\n",
    "        'PRED' : preds,\n",
    "        'UNCERTAINTY' : uncertainties,\n",
    "        'TARGET' : targets\n",
    "        })\n",
    "\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "out_file = 'df_submission.csv'\n",
    "df_submission.to_csv(out_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
